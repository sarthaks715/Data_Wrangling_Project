{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Task 1 in Assessment 1\n",
    "#### Student Name:  Sarthak Sareen\n",
    "#### Student ID: 30761182\n",
    "\n",
    "Date: 13/09/2020\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "* pandas (for dataframe, included in Anaconda Python 2.7) \n",
    "* re (for regular expression, included in Anaconda Python 2.7) \n",
    "* os (interacting with os modules included in Anaconda Python 2.7) \n",
    "* langid (to check string language, included in Anaconda Python 2.7) \n",
    "\n",
    "\n",
    "<font size=3, color=\"red\"> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Indroduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the task we have to analyze the textual data that is the extracting the semi structures files. Each file comtains the id, text and the date created of the tweet.\n",
    "We have to take out the three things i.e id which is a 19 digit number, text which is the actual tweet and the date created that is the dat eat which the tweet was posted.\n",
    "After taking out we have to write all the data to a XML file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing the libraies\n",
    "import os\n",
    "import re\n",
    "import langid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Loading all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading all the file which is present the specified folder path where the file is.txt\n",
    "path = \"Ass-1-5196/\"\n",
    "all_files = os.listdir(path)\n",
    "new_list = []\n",
    "text2 =''\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(root, file), 'r',encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "                #saving the all the text into one string\n",
    "                text2 = text2  + text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Function to perform the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function distribute that will take out the data from the string text2 using regex and returning a dictonary \n",
    "def distribute(data):\n",
    "    #using regex extracting id into a list\n",
    "    list_id = re.findall(r'\"id\":\"[0-9]{19}',data)\n",
    "    #using regex extracting created date into a list\n",
    "    list_created_date = re.findall(r'created_at\":\"[0-9]{4}-[0-9]{2}-[0-9]{2}',data)\n",
    "    #using regex extracting text into a list\n",
    "    list_text = list_text = re.findall(r'\"text\":\".*?\"',data)\n",
    "    #defining a new dictonary\n",
    "    d={}\n",
    "    #adding the first element of the created date list as a key in dictonanry (d) \n",
    "    #with values first element of id list and text list\n",
    "    #first_text = []\n",
    "    first_text = list_text[0].replace(\"//n\",\"/n\")\n",
    "    first_text = first_text.replace(\">\",\"&gt;\")\n",
    "    first_text = first_text.replace(\"&\",\"&amp;\")\n",
    "    first_text = first_text.replace('\"',\"&quot;\")\n",
    "    first_text = first_text.replace(\"'\",\"&apos;\")\n",
    "    d[list_created_date[0].split('\"')[2]] = [[list_id[0].split('\"')[3],first_text]]\n",
    "    #assigning this count for the index which is used to take out the id and text from their lists\n",
    "    count = 0\n",
    "    #loop in created date list\n",
    "    for key in list_created_date:\n",
    "        count= count + 1\n",
    "        if count >= len(list_created_date):\n",
    "            #breaking the loop if count is greater than length of list created date\n",
    "            break\n",
    "        else:\n",
    "            #assigning the id and text to a variable with the help of the count variable as an index\n",
    "            id_element,text_element = list_id[count].split('\"')[3],list_text[count].split('\"')[3]\n",
    "            text_element = text_element.encode('utf-16', 'surrogatepass').decode('utf-16')\n",
    "            text_element = text_element.replace(\"//n\",\"/n\")\n",
    "            text_element = text_element.replace(\"<\",\"&lt;\")\n",
    "            text_element = text_element.replace(\">\",\"&gt;\")\n",
    "            text_element = text_element.replace(\"&\",\"&amp;\")\n",
    "            text_element = text_element.replace('\"',\"&quot;\")\n",
    "            text_element = text_element.replace(\"'\",\"&apos;\")\n",
    "            #checking the text is in english or not. Checking id and text are not empty\n",
    "            if langid.classify(text_element)[0]=='en' and id_element!=\"\" and text_element!=\"\":\n",
    "                keydic = key.split('\"')[2]\n",
    "                #checking the key is present in the dictonary or not\n",
    "                if keydic in d:\n",
    "                    #appending the id and text n the present key\n",
    "                    d[keydic].append([id_element,text_element])\n",
    "                else:\n",
    "                    #making the key and adding the values in it\n",
    "                    d[keydic] = [[id_element,text_element]] \n",
    "            #idf the text is not english then continue\n",
    "            else:\n",
    "                continue\n",
    "    #returning the dictonary\n",
    "    return d  \n",
    "#Calling function distribute function and saving it into final variable\n",
    "final = distribute(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>In the above function the steps followed are :\n",
    "\n",
    "1) The function is taking text which is the combined text of all the files as Data.\n",
    "\n",
    "2) Taking out ID from the text using regex - \"id\":\"[0-9]{19} this means re matches exacty this expression \"id\":\" and then 19 more digits after this. We are taking 19 digits is because we are given that the id is 19 digits. Saving this into list_id.\n",
    "\n",
    "3) Taking out the Created date from the text using regex - created_at\":\"[0-9]{4}-[0-9]{2}-[0-9]{2} this means that re matches exactly this expression created_at\":\" and then 4 digits which are in between 0-9 followed by this expression '-' then 2 digits in between 0-9 follwed by this expression '-' then 2 digits in between 0-9. Saving this regex in list_created date\n",
    "\n",
    "4) Taking out the text from the text using regex - \"text\":\".*?\" this means it matches this expression \"text\":\" then .* means anything ?\" means stop when  we get 0 or 1 this expression \". Saving this into list_text.\n",
    "\n",
    "5) defining a empty dictonary\n",
    "\n",
    "6) Adding the first element of created_date_list as key of the dictonary and values are the list of first element of list_id and first element of list_created. Splitting the three of the to remove the unwanted things in the text.  Such as the created_date_list has first element as 'created_at\" : \"2020-03-23 splitting this to remove the created_date and taking out only 2020-02-23 from it. Performing the same task for id and text.\n",
    "\n",
    "7) Initialising count which will be used for the index to take out theh id element from the list and text.\n",
    "\n",
    "8) Looping in the created_date_list to take this as key of the dictonary.\n",
    "\n",
    "    i) First check is the count should be less that length of the ceated date list because if the count which is used for index       should be in the limit of the created date list length only.\n",
    "      If this happens the loop will break.\n",
    "\n",
    "    ii) Then in the else condition id and text is being assigned to varibles id_element and text_element respectively using the count as the index and splitting the unwanted text from it.\n",
    "    \n",
    "    iii) A) check if the text is english and id_element is not empty and text_element is not empty.\n",
    "         --splitting the created date_list to take out only the date\n",
    "         --checking if the key is already present then append the id_element and text_element as values into the key\n",
    "         --else making the new key and taking id_element and text_element as values into the specific key.\n",
    "   \n",
    "        B) else\n",
    "         --if the text is english and id_element is not empty and text_element is not empty then continue. Notjhing will go                into the new dictonary. This will skip the entry.\n",
    "\n",
    "9) returning the dictonary\n",
    "\n",
    "10) calling the function and saving it into a variable final.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making string \n",
    "stri = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' + '\\n' + '<data>\\n' \n",
    "#iterating in the final dictonary\n",
    "for key,value in final.items():\n",
    "    #adding keys of the dictonary in the string\n",
    "    stri = stri +  '\\t' + '<tweets date=\"'+str(key) + '\">\\n'\n",
    "    #iterating in the values of the dictonary \n",
    "    for i in value:\n",
    "        #adding the tweet id and the text in the string\n",
    "        stri = stri + '\\t\\t' + '<tweet id=\"'+ str(i[0]) + '\">' + str(i[1]) + '</tweet>\\n'\n",
    "    stri = stri + '</tweets>\\n'\n",
    "stri = stri + '</data>'\n",
    "stri= stri.replace(\"\\\\n\",\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell a string is made which contains all the tweets date's tweet id and the text of the specifc date and concating all of the into one string which is stri.\n",
    "in between the string adding the tags of the data , tweet date and tweets to make the text structured liek a XML doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the string into the xml format\n",
    "with open(\"30761182.xml\", \"w\", encoding='utf-8') as text_file:\n",
    "    text_file.write(stri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First reading all the text files into one string.\n",
    "\n",
    "   the string contains all the text of all the files.\n",
    "\n",
    "2) Then using regex extracting id , text , created date :\n",
    "\n",
    "   list_id = [\"id\":\"1234554412323456789,\"id\":\"1234533412341112345,....]\n",
    "   \n",
    "   list_created_date = [\"created date\" :\"2020-03-23,\"created date\":\"2020-04-22,....]\n",
    "   \n",
    "   list_text = [\"text\":\"conrona virus\",\"text\":\"virus is bad\",.....]\n",
    "\n",
    "3) Making a new dictonary with all the handling of the text. The dictonary formed id like :\n",
    "    \n",
    "    { \"2020-03-22\" : [[1233443300987475849.'coronora virus'],[2134443098712345980,'virus is bad'],....] }\n",
    "   \n",
    "4) Then making a string according to the XML document \n",
    "\n",
    "5)  writing the string in the output XMl file.\n",
    "\n",
    "The output file is being creating as xml document having tags and is parsable.\n",
    "   \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
